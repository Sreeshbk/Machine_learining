{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d4a962-ef6a-45a4-8417-932d6b8c66eb",
   "metadata": {},
   "source": [
    "# MLFlow Basics\n",
    "\n",
    "This notebook provides a quick overview of machine learning model training with MLFlow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23dee4-2f19-4358-9d30-1117babdb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    " \n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import mlflow.spark\n",
    "import os\n",
    "import shutil\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "            .config(\"spark.jars.packages\", \"org.mlflow:mlflow-spark:1.11.0\")\n",
    "            .master(\"local[*]\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce380a39-9038-4052-b0d9-d90aaffd339f",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The tutorial uses a dataset describing different wine samples. The dataset is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b23a4d-d399-4523-9e1d-c1a70ba8b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\"\n",
    "red_wine= pd.read_csv(url+'winequality-red.csv', sep=\";\")\n",
    "red_wine['is_red']=1.0\n",
    "white_wine= pd.read_csv(url+'winequality-white.csv', sep=\";\")\n",
    "white_wine['is_red']=0.0\n",
    "data_df = pd.concat([red_wine,white_wine], axis=0)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab1ce5-09e1-4588-b0d8-cea5fa0893c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = data_df['quality'] >=7\n",
    "data = data_df.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faaaea-6dae-4bfd-ad25-40fcc70d8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(data, data_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a8b04-6352-42ad-a610-1562861fa331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://host.docker.internal:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903b1b1-556f-45c5-914b-d2a5ba92fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35714a-3a29-422b-8198-4c6cafe481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='gradient_boost') as run:\n",
    "    model = sklearn.ensemble.GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "    # Models, parameters, and training metrics are tracked automatically\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted_probs = model.predict_proba(X_test)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "\n",
    "    # The AUC score on test data is not automatically logged, so log it manually\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc)\n",
    "    print(\"Test AUC of: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30513e6-9e6c-4a00-9187-56e193bbf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='gradient_boost') as run:\n",
    "    model_2 = sklearn.ensemble.GradientBoostingClassifier(random_state=0, n_estimators =200)\n",
    "\n",
    "    # Models, parameters, and training metrics are tracked automatically\n",
    "    model_2.fit(X_train, y_train)\n",
    "\n",
    "    predicted_probs = model_2.predict_proba(X_test)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "\n",
    "    # The AUC score on test data is not automatically logged, so log it manually\n",
    "    mlflow.log_metric(\"test_auc\", roc_auc)\n",
    "    print(\"Test AUC of: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb82ed-ee84-45c9-85a2-9db7a70370ff",
   "metadata": {},
   "source": [
    "![MLFlow](\"./images/mlflow_gradientboost.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455e9bd-18c8-4c41-8fee-92578eee52de",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e39e7-7193-4f11-b55a-1dd70797aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After a model has been logged, you can load it in different notebooks or jobs\n",
    "# mlflow.pyfunc.load_model makes model prediction available under a common API\n",
    "model_loaded = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=run.info.run_id\n",
    "  )\n",
    ")\n",
    " \n",
    "predictions_loaded = model_loaded.predict(X_test)\n",
    "predictions_original = model_2.predict(X_test)\n",
    " \n",
    "# The loaded model should match the original\n",
    "assert(np.array_equal(predictions_loaded, predictions_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5a3a8-cbd2-4261-904d-748d744ed693",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326d332-b627-4053-9d8f-c43b5d75c454",
   "metadata": {},
   "source": [
    "## Hyperopt\n",
    "Hyperopt is a Python library for hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888c2106-ac83-479f-a029-1a89213af45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [01:05<02:47,  7.29s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:37:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:37:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:37:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [01:09<02:18,  6.30s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:37:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:37:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:37:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [01:16<02:18,  6.58s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:37:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:37:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:37:39 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [01:23<02:10,  6.51s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:37:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:37:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:37:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [01:33<02:26,  7.72s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:37:56 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:37:56 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:37:56 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [01:42<02:24,  8.01s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [01:47<02:01,  7.15s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [01:53<01:49,  6.81s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:16 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:16 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:16 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [01:58<01:31,  6.13s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [02:05<01:28,  6.35s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:27 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:27 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:27 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [02:08<01:10,  5.39s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [02:16<01:13,  6.11s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [02:21<01:03,  5.78s/trial, best loss: -0.9034264687141583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [02:35<01:23,  8.35s/trial, best loss: -0.9059991079393398]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:38:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:38:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:38:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [02:51<01:35, 10.56s/trial, best loss: -0.9067199248120301]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:39:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:39:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:39:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [03:06<01:37, 12.14s/trial, best loss: -0.9067876258442717]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:39:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [03:21<01:30, 12.90s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:39:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:39:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:39:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [03:35<01:18, 13.13s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:39:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:39:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:39:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [03:49<01:06, 13.40s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:40:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:40:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:40:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [04:02<00:52, 13.24s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:40:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:40:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:40:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [04:14<00:38, 12.95s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:40:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:40:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:40:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [04:25<00:24, 12.30s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:40:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:40:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:40:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [04:39<00:13, 13.04s/trial, best loss: -0.9101647126290302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/12 03:41:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "\n",
      "2022/12/12 03:41:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "\n",
      "2022/12/12 03:41:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [04:50<00:00,  9.09s/trial, best loss: -0.9101647126290302]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the search space to explore\n",
    "search_space = {\n",
    "  'n_estimators': scope.int(hp.quniform('n_estimators', 20, 1000, 1)),\n",
    "  'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "  'max_depth': scope.int(hp.quniform('max_depth', 2, 5, 1)),\n",
    "}\n",
    " \n",
    "def train_model(params):\n",
    "    \n",
    "    # Enable autologging on each worker\n",
    "    mlflow.autolog()\n",
    "    with mlflow.start_run(run_name='inner_run', nested=True):\n",
    "        model_hp = sklearn.ensemble.GradientBoostingClassifier(\n",
    "          random_state=0,\n",
    "          **params\n",
    "        )\n",
    "        model_hp.fit(X_train, y_train)\n",
    "        predicted_probs = model_hp.predict_proba(X_test)\n",
    "        # Tune based on the test AUC\n",
    "        # In production settings, you could use a separate validation set instead\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_test, predicted_probs[:,1])\n",
    "        mlflow.log_metric('test_auc', roc_auc)\n",
    "    \n",
    "    # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "    return {'status': STATUS_OK, 'loss': -1*roc_auc}\n",
    " \n",
    "# SparkTrials distributes the tuning using Spark workers\n",
    "# Greater parallelism speeds processing, but each hyperparameter trial has less information from other trials\n",
    "# On smaller clusters or Databricks Community Edition try setting parallelism=2\n",
    "#spark_trials = SparkTrials(\n",
    "#  parallelism=8\n",
    "#)\n",
    "spark_trials =Trials() \n",
    " \n",
    "with mlflow.start_run(run_name='gb_hyperopt') as run:\n",
    "  # Use hyperopt to find the parameters yielding the highest AUC\n",
    "  best_params = fmin(\n",
    "    fn=train_model, \n",
    "    space=search_space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=32,\n",
    "    trials=spark_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ef5e8-351c-49ec-80fa-2386dac47e60",
   "metadata": {},
   "source": [
    "## Search runs to retrieve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fabe777-ebff-4683-afb1-6f25419e49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run\n",
      "AUC: 0.9101647126290302\n",
      "Num Estimators: 949\n",
      "Max Depth: 5\n",
      "Learning Rate: 0.32079649376965114\n",
      "Test Predictions: [False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Sort runs by their test auc; in case of ties, use the most recent run\n",
    "best_run = mlflow.search_runs(\n",
    "  order_by=['metrics.test_auc DESC', 'start_time DESC'],\n",
    "  max_results=10,\n",
    ").iloc[0]\n",
    "print('Best Run')\n",
    "print('AUC: {}'.format(best_run[\"metrics.test_auc\"]))\n",
    "print('Num Estimators: {}'.format(best_run[\"params.n_estimators\"]))\n",
    "print('Max Depth: {}'.format(best_run[\"params.max_depth\"]))\n",
    "print('Learning Rate: {}'.format(best_run[\"params.learning_rate\"]))\n",
    " \n",
    "best_model_pyfunc = mlflow.pyfunc.load_model(\n",
    "  'runs:/{run_id}/model'.format(\n",
    "    run_id=best_run.run_id\n",
    "  )\n",
    ")\n",
    "best_model_predictions = best_model_pyfunc.predict(X_test[:5])\n",
    "print(\"Test Predictions: {}\".format(best_model_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc709949-6510-4754-b327-fe9e97cb71e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
